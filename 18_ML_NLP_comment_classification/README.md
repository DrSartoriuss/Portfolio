# Определение токсичности комментариев

## Описание проекта 

- Интернет-магазин «Викишоп» запускает пользовательский интерактивный сервис комментирования описаний товаров. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. В нашем распоряжении набор данных с разметкой о токсичности правок. Нам нужно модель классифицировать комментарии на позитивные и негативные, со значением метрики качества *F1* не меньше *0.75.*  

## Используемые инструменты:
 
*Библиотеки:*

- pandas
- numpy
- matplotlib
- torch
- re
- nltk
- chardet
- transformers
- tqdm
- imblearn
- wordcloud
- sklearn
- catboost

*Модели:*

- DistilBertModel
- LogisticRegression
- RandomForestClassificier
- CatBoostClassificier
- DummyClassifier


## Результаты: 

- Мы загрузили данные и провели их подготовку двумя методами: TF-IDF и BERT. На подготовленных по-разному данных мы обучили разные модели, попробовав для каждой разные гиперпараметры и проверили качество лучшей модели на тестовой выборке.

- Быстрее и лучше других с задачей справилась модель LogisticRegression с TF-IDF, показав лучшее качество предсказания на тестовой выборке (**F1 - 0.7613**). Модель вменяема. Ее можно рекомендовать заказчику.
